# -*- coding: utf-8 -*-
"""BTVN_CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aYkEofZzwyYH5WQMW3LqKCPaEeI4_i5b

# *1. MNIST_CNN*

*Load data*
"""

from keras.datasets import mnist
from tensorflow.keras.optimizers import RMSprop
import numpy as np
from keras.utils import np_utils
import matplotlib.pyplot as plt

(x_train, y_train), (x_test, y_test) = mnist.load_data()

for i in range(9):
  plt.subplot(330+1+i)
  plt.imshow(x_train[i], cmap = plt.get_cmap('gray'))
plt.show()

x_train.shape

"""*Reshape data*"""

x_train = x_train.reshape(60000, 28, 28, 1)
x_test = x_test.reshape(10000, 28, 28, 1)

x_train = x_train.astype('float32')
x_test = x_test.astype('float32')

x_train /= 255 #ve mau xam (in range(0-1))
x_test /= 255

y_train = np_utils.to_categorical(y_train)
y_test = np_utils.to_categorical(y_test)

y_train.shape

"""*Create layer model*"""

from keras.models import Sequential
from keras.layers import Dense, Dropout, MaxPooling2D, Conv2D, Flatten

#Block 1
model = Sequential()
model.add(Conv2D(32, (3,3), activation = 'relu', kernel_initializer='he_uniform', 
                 padding = 'same', input_shape = (28,28,1)))
model.add(Conv2D(32, (3,3), activation = 'relu', kernel_initializer='he_uniform', 
                 padding = 'same'))
model.add(MaxPooling2D((2,2)))

#Block 2
model.add(Conv2D(64,(3,3),activation='relu',kernel_initializer='he_uniform',padding='same')) 
model.add(Conv2D(64,(3,3),activation='relu',kernel_initializer='he_uniform',padding='same'))
model.add(MaxPooling2D((2,2)))

#Block 3
model.add(Conv2D(128,(3,3),activation='relu',kernel_initializer='he_uniform',padding='same')) 
model.add(Conv2D(128,(3,3),activation='relu',kernel_initializer='he_uniform',padding='same')) 
model.add(MaxPooling2D((2,2)))

model.add(Flatten())
model.add(Dense(128,activation='relu',kernel_initializer='he_uniform'))
# model.add(Dropout(0.2))
model.add(Dense(64, activation= 'relu'))
# model.add(Dropout(0.2))
model.add(Dense(10,activation='softmax'))
model.summary()

"""*Training*"""

model.compile(loss='categorical_crossentropy', optimizer = RMSprop(), metrics = 'accuracy')
history = model.fit(x_train, y_train, epochs = 5, batch_size = 128, validation_data = (x_test, y_test))

"""*Save model*"""

model.save('CNN_mnist.h5')

"""*Evaluate Model*"""

score = model.evaluate(x_test, y_test, verbose = 0)
print('Sai so kiem tra la:', score[0])
print('Do chinh xac kiem tra la: ', score[1])

"""*Diagram*"""

import pandas as pd

pd.DataFrame(history.history).plot(figsize = (8,5))
plt.grid(True)
plt.gca().set_ylim(0,1.2)
plt.show()

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train','validation'], loc = 'upper left')
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train','validation'], loc = 'upper left')
plt.show()

"""# *2. FASHION MNIST*

*Load data*
"""

from keras.datasets import fashion_mnist
import numpy as np
from keras.utils import np_utils
import matplotlib.pyplot as plt

#load dữ liệu: fashion_mnist datasets
(x_train, y_train),(x_test,y_test) = fashion_mnist.load_data()

#hiển thị dữ liệu mẫu
for i in range(9):
  plt.subplot(330+1+i)
  plt.imshow(x_train[i], cmap = plt.get_cmap('gray'))
plt.show()

"""*Reshape data*"""

x_train = x_train.reshape(60000,28,28,1)
x_test = x_test.reshape(10000, 28,28,1)
x_train = x_train.astype('float32')
x_test = x_test.astype('float32')

x_train /= 255
x_test /= 255

y_train = np_utils.to_categorical(y_train)
y_test = np_utils.to_categorical(y_test)

"""*Add layers*"""

from keras.models import Sequential
from keras.layers import Dense, Dropout, MaxPooling2D, Conv2D, Flatten

#Block 1
model = Sequential()
model.add(Conv2D(32, (3,3), activation = 'relu', kernel_initializer='he_uniform', 
                 padding = 'same', input_shape = (28,28,1)))
model.add(MaxPooling2D((2,2)))

#Block 2
model.add(Conv2D(64,(3,3),activation='relu',kernel_initializer='he_uniform',padding='same')) 
model.add(MaxPooling2D((2,2)))

#Block 3
model.add(Conv2D(128,(3,3),activation='relu',kernel_initializer='he_uniform',padding='same')) 
model.add(MaxPooling2D((2,2)))

model.add(Flatten())
model.add(Dense(128,activation='relu',kernel_initializer='he_uniform'))
model.add(Dense(64, activation= 'relu'))
model.add(Dense(10,activation='softmax'))
model.summary()

"""*Training*"""

model.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics = 'accuracy')
history = model.fit(x_train, y_train, epochs = 10, batch_size = 128, validation_data = (x_test, y_test))

"""*Evaluate model*"""

score = model.evaluate(x_test, y_test, verbose = 0)
print('Sai so kiem tra la:', score[0])
print('Do chinh xac kiem tra la: ', score[1])

"""*Diagram*"""

import pandas as pd

pd.DataFrame(history.history).plot(figsize = (8,5))
plt.grid(True)
plt.title('Acc & Loss Diagram')
plt.xlabel('epoch')
plt.gca().set_ylim(0,1.2)
plt.show()

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train','validation'], loc = 'upper left')
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train','validation'], loc = 'upper left')
plt.show()

"""*Save model*"""

model.save('CNN_fashionmnist.h5')

"""*Predict*"""

# Testing code with ANN model
from tensorflow.keras import datasets,layers,models
from keras.preprocessing import image
from keras.models import load_model
from keras.preprocessing.image import load_img, img_to_array 
import numpy as np
import array

model_fashionmnist = load_model('CNN_fashionmnist.h5')
# Load and define image - to test
img = load_img('shirt_test.jpg', target_size=(28,28))
plt.imshow(img)

img=image.img_to_array(img) 
img=img[:,:,0]
img=img.reshape(1,28,28,1)
img=img.astype('float32')
img=img/255

labels = ['t-shirt','trouser','pullover','dress','coat','sandal','shirt','sneaker',
          'bag', 'ankle boot']
guess = np.argmax(model_fashionmnist.predict(img),axis=1)
for i in range(10):
  if guess==[i]:
    guess=i
print('This is a: ', labels[guess])

"""# *3. OWN FACE*

*Import library*
"""

import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.preprocessing.image import  ImageDataGenerator
import matplotlib.pyplot as plt

from __future__ import absolute_import, division, print_function, unicode_literals
import matplotlib.pylab as plt
import tensorflow as tf
import pandas as pd
from tensorflow.keras import datasets,layers,models
import matplotlib.pyplot as plt
from keras.utils import np_utils
from keras.models import Sequential
from keras.layers import Dense,Activation,Flatten, Conv2D, MaxPooling2D
from tensorflow.keras.optimizers import SGD,RMSprop,Adam

"""*Mount with google drive*"""

from google.colab import drive
drive.mount('/content/gdrive', force_remount=True)

"""*Set data path*"""

dataset_path = '/content/gdrive/MyDrive/Colab-Notebooks/FaceImage'

"""*Split data for train and test*"""

image_size = (150,150)
TRAINING_DATA_DIR = str(dataset_path)
print(TRAINING_DATA_DIR)

# modify data
kwargs_datagen = dict(rescale=1./255, validation_split=0.2) # 20 percent for validation

# validation data modify 
valid_datagen = ImageDataGenerator(**kwargs_datagen)
valid_generator = valid_datagen.flow_from_directory(TRAINING_DATA_DIR, subset="validation", 
                                                    shuffle=True, target_size=image_size)

# train data modify
train_datagen = ImageDataGenerator(**kwargs_datagen)
train_generator = train_datagen.flow_from_directory(TRAINING_DATA_DIR,subset="training",
                                                    shuffle=True,target_size=image_size)

"""*Match data with labels*"""

image_batch_train, label_batch_train = next(iter(train_generator))
print("image batch shape: ", image_batch_train.shape)
print("label batch shape: ", label_batch_train.shape)
dataset_labels = sorted(train_generator.class_indices.items(), key=lambda pair:pair[1])
dataset_labels = np.array([key.title() for key, value in dataset_labels])
print("labels: ", dataset_labels)
print("match class: ", train_generator.class_indices)

"""*Add layers*"""

# Create layer model with CNN

model1=Sequential()
# BLock 1
model1.add(Conv2D(32,(3,3),activation='relu',kernel_initializer='he_uniform',padding='same',
                  input_shape=(150,150,3))) 
model1.add(Conv2D(32,(3,3),activation='relu',kernel_initializer='he_uniform',padding='same')) 
model1.add(MaxPooling2D((2,2)))
#Block 2
model1.add(Conv2D(64,(3,3),activation='relu',kernel_initializer='he_uniform',padding='same')) 
model1.add(Conv2D(64,(3,3),activation='relu',kernel_initializer='he_uniform',padding='same'))
model1.add(MaxPooling2D((2,2)))
#Block 3
model1.add(Conv2D(128,(3,3),activation='relu',kernel_initializer='he_uniform',padding='same')) 
model1.add(Conv2D(128,(3,3),activation='relu',kernel_initializer='he_uniform',padding='same')) 
model1.add(MaxPooling2D((2,2)))

model1.add(Flatten())
model1.add(Dense(512,activation='relu',kernel_initializer='he_uniform'))
model1.add(Dense(128,activation='relu'))
model1.add(Dense(2,activation='softmax'))
model1.summary()

"""*Training*"""

#Training
# opt=SGD(learning_rate=0.01,momentum=0.9)
model1.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

steps_per_epoch = np.ceil(train_generator.samples/train_generator.batch_size)
history1=model1.fit(train_generator,epochs=5,batch_size=4,validation_data=valid_generator,
                    steps_per_epoch=steps_per_epoch,verbose=1)

# Save model
model1.save('CNN_OwnFaceDetect.h5')

"""*Evaluate accuracy*"""

score = model1.evaluate(train_generator, verbose = 0)
print('sai so kiem tra la: ', score[0])
print('do chinh xac kiem tra la: ', score[1])

"""*Diagram*"""

import pandas as pd

pd.DataFrame(history1.history).plot(figsize = (8,5))
plt.grid(True)
plt.title('Acc & Loss Diagram')
plt.xlabel('epoch')
plt.gca().set_ylim(0,1.2)
plt.show()

plt.plot(history1.history['accuracy'])
plt.plot(history1.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train','validation'], loc = 'upper left')
plt.show()

plt.plot(history1.history['loss'])
plt.plot(history1.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train','validation'], loc = 'upper left')
plt.show()

"""*Prediction*"""

import matplotlib.pyplot as plt
from tensorflow.keras import datasets,layers,models
from keras.preprocessing import image
from keras.models import load_model
from keras.preprocessing.image import load_img, img_to_array 
import numpy as np


# Load and define image - to test
img = load_img('test.jpg', target_size=(150,150))
plt.imshow(img)
img=image.img_to_array(img) 
img=img.reshape(1,150,150,3)
img=img.astype('float32')
img=img/255

model_ownface = load_model('CNN_OwnFaceDetect.h5')
# predict 
guess=np.argmax(model_ownface.predict(img),axis=1)
if guess[0]==0:
  print("It's me ✅")
if guess[0]==1:
  print("others 👨")

import matplotlib.pyplot as plt
from tensorflow.keras import datasets,layers,models
from keras.preprocessing import image
from keras.models import load_model
from keras.preprocessing.image import load_img, img_to_array 

model_ownface = load_model('CNN_OwnFaceDetect.h5')
# Load and define image - to test
img = load_img('4.jpg', target_size=(150,150))
plt.imshow(img)
img=image.img_to_array(img) 
img=img.reshape(1,150,150,3)
img=img.astype('float32')
img=img/255

# predict 
guess=np.argmax(model_ownface.predict(img),axis=1)
if guess[0]==0:
  print("It's me ✅")
if guess[0]==1:
  print("others 👨")

"""# *4. CIFAR100*

*Load data*
"""

import tensorflow as tf
import matplotlib.pyplot as plt
from tensorflow.keras import datasets, layers, models


(x_train, y_train),(x_test, y_test) = datasets.cifar100.load_data()
for i in range (9):
  plt.subplot(331+i)
  plt.imshow(x_train[i])
plt.show()

"""*Gray scale*"""

from keras.utils import np_utils


x_train = x_train.astype('float32')
x_test = x_test.astype('float32')
x_train /= 255
x_test /= 255

# y_train = np_utils.to_categorical(y_train)
# y_test = np_utils.to_categorical(y_test)

print(x_train.shape, x_test.shape)
print(y_train.shape, y_test.shape)

"""*Add layers*"""

from keras.models import Sequential
from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D

model = Sequential()
model.add(Conv2D(32, (3,3), activation = 'relu', kernel_initializer='he_uniform', 
                 padding = 'same', input_shape = (32,32,3)))
model.add(Conv2D(32, (3,3), activation = 'relu', kernel_initializer='he_uniform', padding = 'same'))
model.add(MaxPooling2D((2,2)))

model.add(Conv2D(64, (3,3), activation = 'relu', kernel_initializer='he_uniform', padding = 'same'))
model.add(Conv2D(64, (3,3), activation = 'relu', kernel_initializer='he_uniform', padding = 'same'))
model.add(MaxPooling2D((2,2)))

model.add(Conv2D(128, (3,3), activation = 'relu', kernel_initializer='he_uniform', padding = 'same'))
model.add(Conv2D(128, (3,3), activation = 'relu', kernel_initializer='he_uniform', padding = 'same'))
model.add(MaxPooling2D((2,2)))

model.add(Flatten())
model.add(Dense(128, activation = 'relu', kernel_initializer='he_uniform'))
model.add(Dense(100, activation='softmax'))
model.summary()

"""*Training*"""

from tensorflow.keras.optimizers import SGD

opt = SGD(lr=0.01, momentum=0.9)
model.compile(optimizer=opt, loss = 'categorical_crossentropy', metrics=['accuracy'])
history = model.fit(x_train, y_train, epochs= 10, batch_size=128, validation_data = (x_test, y_test), verbose = 1)

"""*Save model*"""

model.save('CNN_cifar100.h5')

"""*Load model*"""

model_cifar100 = load_model('CNN_cifar100.h5')

"""*Diagram*"""

# Evaluate
# score = model_cifar100.evaluate(x_test, y_test, verbose = 0)
# print('sai so kiem tra la: ', score[0])
# print('do chinh xac kiem tra la: ', score[1])

import pandas as pd

pd.DataFrame(history.history).plot(figsize = (8,5))
plt.title('')
plt.grid(True)
plt.gca().set_ylim(0,1)
plt.show()

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train acc', 'val acc'], loc = 'upper left')
plt.show()


plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train loss', 'val loss'], loc = 'upper left')
plt.show()

"""*Predict*"""

import matplotlib.pyplot as plt
from tensorflow.keras import datasets,layers,models
from keras.preprocessing import image
from keras.models import load_model
from keras.preprocessing.image import load_img, img_to_array 
import numpy as np
import array


# Load and define image - to test
img = load_img('wolf.jpg', target_size=(32,32))
plt.imshow(img)

img=image.img_to_array(img) 
# img=img[:,:,0]
img=img.reshape(1,32,32,3)
img=img.astype('float32')
img=img/255

labels = {0: 'apple',
1: 'aquarium_fish',
2: 'baby',
3: 'bear', 
4: 'beaver', 
5: 'bed', 
6: 'bee', 
7: 'beetle', 
8: 'bicycle',
9: 'bottle',
10:'bowl',
11: 'boy',
12: 'bridge',
13: 'bus',
14: 'butterfly',
15: 'camel',
16: 'can',
17: 'castle',
18: 'caterpillar',
19: 'cattle',
20: 'chair',
21: 'chimpanzee',
22: 'clock',
23: 'cloud',
24: 'cockroach',
25:'couch',
26: 'cra',
27: 'crocodile',
28:'cup',
29: 'dinosaur',
30: 'dolphin',
31: 'elephant',
32: 'flatfish',
33: 'forest',
34: 'fox',
35: 'girl',
36: 'hamster',
37: 'house',
38: 'kangaroo',
39: 'keyboard',
40: 'lamp',
41: 'lawn_mower',
42: 'leopard',
43: 'lion',
44: 'lizard',
45: 'lobster',
46: 'man',
47: 'maple_tree',
48: 'motorcycle',
49: 'mountain',
50: 'mouse',
51: 'mushroom',
52: 'oak_tree',
53: 'orange',
54: 'orchid',
55: 'otter',
56: 'palm_tree',
57: 'pear',
58: 'pickup_truck',
59: 'pine_tree',
60: 'plain',
61: 'plate',
62: 'poppy',
63: 'porcupine',
64: 'possum',
65: 'rabbit',
66: 'raccoon',
67: 'ray',
68: 'road',
69: 'rocket',
70: 'rose',
71: 'sea',
72: 'seal',
73: 'shark',
74: 'shrew',
75: 'skunk',
76: 'skyscraper',
77: 'snail',
78: 'snake',
79: 'spider',
80: 'squirrel',
81: 'streetcar',
82: 'sunflower',
83: 'sweet_pepper',
84: 'table',
85: 'tank',
86: 'telephone',
87: 'television',
88: 'tiger',
89: 'tractor',
90: 'train',
91: 'trout',
92: 'tulip',
93: 'turtle',
94: 'wardrobe',
95: 'whale',
96: 'willow_tree',
97: 'wolf',
98: 'woman',
99: 'worm'}
guess = np.argmax(model_cifar100.predict(img),axis=1)
for i in range(100):
  if guess==[i]:
    guess=i
print('This is a: ', labels[guess])



from tensorflow.keras.optimizers import SGD

opt = SGD(lr=0.01, momentum=0.9)
model.compile(optimizer=opt, loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])
history = model.fit(x_train, y_train, epochs= 20, batch_size=64, validation_data = (x_test, y_test), verbose = 1)

model.save('CNN_cifar100_02.h5')

model_cifar100_02 = load_model('CNN_cifar100_02.h5')

# Evaluate
score = model_cifar100_02.evaluate(x_test, y_test, verbose = 0)
print('sai so kiem tra la: ', score[0])
print('do chinh xac kiem tra la: ', score[1])

import pandas as pd

pd.DataFrame(history.history).plot(figsize = (8,5))
plt.title('')
plt.grid(True)
plt.gca().set_ylim(0,1)
plt.show()

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train acc', 'val acc'], loc = 'upper left')
plt.show()


plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train loss', 'val loss'], loc = 'upper left')
plt.show()

import matplotlib.pyplot as plt
from tensorflow.keras import datasets,layers,models
from keras.preprocessing import image
from keras.models import load_model
from keras.preprocessing.image import load_img, img_to_array 
import numpy as np
import array


# Load and define image - to test
img = load_img('wolf.jpg', target_size=(32,32))
plt.imshow(img)

img=image.img_to_array(img) 
img=img.reshape(1,32,32,3)
img=img.astype('float32')
img=img/255

labels = {0: 'apple',
1: 'aquarium_fish',
2: 'baby',
3: 'bear', 
4: 'beaver', 
5: 'bed', 
6: 'bee', 
7: 'beetle', 
8: 'bicycle',
9: 'bottle',
10:'bowl',
11: 'boy',
12: 'bridge',
13: 'bus',
14: 'butterfly',
15: 'camel',
16: 'can',
17: 'castle',
18: 'caterpillar',
19: 'cattle',
20: 'chair',
21: 'chimpanzee',
22: 'clock',
23: 'cloud',
24: 'cockroach',
25:'couch',
26: 'cra',
27: 'crocodile',
28:'cup',
29: 'dinosaur',
30: 'dolphin',
31: 'elephant',
32: 'flatfish',
33: 'forest',
34: 'fox',
35: 'girl',
36: 'hamster',
37: 'house',
38: 'kangaroo',
39: 'keyboard',
40: 'lamp',
41: 'lawn_mower',
42: 'leopard',
43: 'lion',
44: 'lizard',
45: 'lobster',
46: 'man',
47: 'maple_tree',
48: 'motorcycle',
49: 'mountain',
50: 'mouse',
51: 'mushroom',
52: 'oak_tree',
53: 'orange',
54: 'orchid',
55: 'otter',
56: 'palm_tree',
57: 'pear',
58: 'pickup_truck',
59: 'pine_tree',
60: 'plain',
61: 'plate',
62: 'poppy',
63: 'porcupine',
64: 'possum',
65: 'rabbit',
66: 'raccoon',
67: 'ray',
68: 'road',
69: 'rocket',
70: 'rose',
71: 'sea',
72: 'seal',
73: 'shark',
74: 'shrew',
75: 'skunk',
76: 'skyscraper',
77: 'snail',
78: 'snake',
79: 'spider',
80: 'squirrel',
81: 'streetcar',
82: 'sunflower',
83: 'sweet_pepper',
84: 'table',
85: 'tank',
86: 'telephone',
87: 'television',
88: 'tiger',
89: 'tractor',
90: 'train',
91: 'trout',
92: 'tulip',
93: 'turtle',
94: 'wardrobe',
95: 'whale',
96: 'willow_tree',
97: 'wolf',
98: 'woman',
99: 'worm'}
guess = np.argmax(model_cifar100_02.predict(img),axis=1)
for i in range(100):
  if guess==[i]:
    guess=i
print('This is a: ', labels[guess])

"""# *5. 10 FRUITS*"""

import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.preprocessing.image import  ImageDataGenerator
import matplotlib.pyplot as plt

from __future__ import absolute_import, division, print_function, unicode_literals
import matplotlib.pylab as plt
import tensorflow as tf
import pandas as pd
from tensorflow.keras import datasets,layers,models
import matplotlib.pyplot as plt
from keras.utils import np_utils
from keras.models import Sequential
from keras.layers import Dense,Activation,Flatten, Conv2D, MaxPooling2D
from tensorflow.keras.optimizers import SGD,RMSprop,Adam

from google.colab import drive
drive.mount('/content/gdrive', force_remount=True)

dataset_path = '/content/gdrive/MyDrive/Colab-Notebooks/Fruit'

"""*Load model*"""

image_size = (100,100)
TRAINING_DATA_DIR = str(dataset_path)
print(TRAINING_DATA_DIR)

# modify data
kwargs_datagen = dict(rescale=1./255, validation_split=0.2) # 20 percent for validation

# validation data modify 
valid_datagen = ImageDataGenerator(**kwargs_datagen)
valid_generator = valid_datagen.flow_from_directory(TRAINING_DATA_DIR, subset="validation", 
                                                    shuffle=True, target_size=image_size)

# train data modify
train_datagen = ImageDataGenerator(**kwargs_datagen)
train_generator = train_datagen.flow_from_directory(TRAINING_DATA_DIR,subset="training",
                                                    shuffle=True,target_size=image_size)

"""*Match class*"""

image_batch_train, label_batch_train = next(iter(train_generator))
print("image batch shape: ", image_batch_train.shape)
print("label batch shape: ", label_batch_train.shape)
dataset_labels = sorted(train_generator.class_indices.items(), key=lambda pair:pair[1])
dataset_labels = np.array([key.title() for key, value in dataset_labels])
print("labels: ", dataset_labels)
print("match class: ", train_generator.class_indices)

"""*Add layers*"""

# Create layer model with CNN

model1=Sequential()
# BLock 1
model1.add(Conv2D(32,(3,3),activation='relu',kernel_initializer='he_uniform',padding='same',
                  input_shape=(100,100,3))) 
model1.add(Conv2D(32,(3,3),activation='relu',kernel_initializer='he_uniform',padding='same')) 
model1.add(MaxPooling2D((2,2)))
#Block 2
model1.add(Conv2D(64,(3,3),activation='relu',kernel_initializer='he_uniform',padding='same')) 
model1.add(Conv2D(64,(3,3),activation='relu',kernel_initializer='he_uniform',padding='same'))
model1.add(MaxPooling2D((2,2)))
#Block 3
model1.add(Conv2D(128,(3,3),activation='relu',kernel_initializer='he_uniform',padding='same')) 
model1.add(Conv2D(128,(3,3),activation='relu',kernel_initializer='he_uniform',padding='same')) 
model1.add(MaxPooling2D((2,2)))

model1.add(Flatten())
model1.add(Dense(512,activation='relu',kernel_initializer='he_uniform'))
model1.add(Dense(128,activation='relu'))
model1.add(Dense(10,activation='softmax'))
model1.summary()

"""*Training*"""

#Training

model1.compile(loss='categorical_crossentropy',optimizer=Adam(),metrics=['accuracy'])

steps_per_epoch = np.ceil(train_generator.samples/train_generator.batch_size)
history1=model1.fit(train_generator,epochs=4,batch_size=32,validation_data=valid_generator,
                    steps_per_epoch=steps_per_epoch,verbose=1)

# Save model
model1.save('CNN_FruitDetect.h5')

"""*Evaluate model*"""

score = model1.evaluate(train_generator, verbose = 0)
print('sai so kiem tra la: ', score[0])
print('do chinh xac kiem tra la: ', score[1])

"""*Diagram*"""

import pandas as pd
pd.DataFrame(history1.history).plot(figsize = (8,5))
plt.grid(True)
plt.title('Acc & Loss Diagram')
plt.xlabel('epoch')
plt.gca().set_ylim(0,1.2)
plt.show()

plt.plot(history1.history['accuracy'])
plt.plot(history1.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train','validation'], loc = 'upper left')
plt.show()
plt.plot(history1.history['loss'])
plt.plot(history1.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train','validation'], loc = 'upper left')
plt.show()

from keras.models import load_model
model_fruit = load_model('CNN_FruitDetect.h5')

"""*Predict*"""

import matplotlib.pyplot as plt
from tensorflow.keras import datasets,layers,models
from keras.preprocessing import image
from keras.models import load_model
from keras.preprocessing.image import load_img, img_to_array 
import numpy as np
import array



# Load and define image - to test
img = load_img('chuoi_test.jpg', target_size=(100,100))
plt.imshow(img)

img=image.img_to_array(img) 
img=img.reshape(1,100,100,3)
img=img.astype('float32')
img=img/255

guess = np.argmax(model_fruit.predict(img),axis=1)
print(' This fruit is: ' , dataset_labels[guess])



"""# *6. Money*"""

dataset_path = '/content/gdrive/MyDrive/Colab-Notebooks/Money'

"""*Split data*"""

image_size = (250,250)
TRAINING_DATA_DIR = str(dataset_path)
print(TRAINING_DATA_DIR)

# modify data
kwargs_datagen = dict(rescale=1./255, validation_split=0.2) # 20 percent for validation

# validation data modify 
valid_datagen = ImageDataGenerator(**kwargs_datagen)
valid_generator = valid_datagen.flow_from_directory(TRAINING_DATA_DIR, subset="validation", 
                                                    shuffle=True, target_size=image_size)

# train data modify
train_datagen = ImageDataGenerator(**kwargs_datagen)
train_generator = train_datagen.flow_from_directory(TRAINING_DATA_DIR,subset="training",
                                                    shuffle=True,target_size=image_size)

"""*Match labels*"""

image_batch_train, label_batch_train = next(iter(train_generator))
print("image batch shape: ", image_batch_train.shape)
print("label batch shape: ", label_batch_train.shape)
dataset_labels = sorted(train_generator.class_indices.items(), key=lambda pair:pair[1])
dataset_labels = np.array([key.title() for key, value in dataset_labels])
print("labels: ", dataset_labels)
print("match class: ", train_generator.class_indices)

"""*Add layers*"""

# Create layer model with CNN

model1=Sequential()
# BLock 1
model1.add(Conv2D(32,(3,3),activation='relu',kernel_initializer='he_uniform',padding='same',
                  input_shape=(250,250,3))) 
model1.add(MaxPooling2D((2,2)))
#Block 2
model1.add(Conv2D(64,(3,3),activation='relu',kernel_initializer='he_uniform',padding='same')) 
model1.add(MaxPooling2D((2,2)))
#Block 3
model1.add(Conv2D(128,(3,3),activation='relu',kernel_initializer='he_uniform',padding='same')) 
model1.add(MaxPooling2D((2,2)))

model1.add(Flatten())
model1.add(Dense(512,activation='relu',kernel_initializer='he_uniform'))
model1.add(Dense(128,activation='relu'))
model1.add(Dense(10,activation='softmax'))
model1.summary()

"""*Training*"""

#Training

model1.compile(loss='categorical_crossentropy',optimizer=Adam(),metrics=['accuracy'])

steps_per_epoch = np.ceil(train_generator.samples/train_generator.batch_size)
history1=model1.fit(train_generator,epochs=4,batch_size=32,validation_data=valid_generator,
                    steps_per_epoch=steps_per_epoch,verbose=1)

# Save model
model1.save('CNN_MoneyDetect.h5')

"""*Evaluate model*"""

score = model1.evaluate(train_generator, verbose = 0)
print('sai so kiem tra la: ', score[0])
print('do chinh xac kiem tra la: ', score[1])

"""*Diagram*"""

import pandas as pd
pd.DataFrame(history1.history).plot(figsize = (8,5))
plt.grid(True)
plt.title('Acc & Loss Diagram')
plt.xlabel('epoch')
plt.gca().set_ylim(0,1.2)
plt.show()

plt.plot(history1.history['accuracy'])
plt.plot(history1.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train','validation'], loc = 'upper left')
plt.show()
plt.plot(history1.history['loss'])
plt.plot(history1.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train','validation'], loc = 'upper left')
plt.show()

"""*Predict*"""

import matplotlib.pyplot as plt
from tensorflow.keras import datasets,layers,models
from keras.preprocessing import image
from keras.models import load_model
from keras.preprocessing.image import load_img, img_to_array 
import numpy as np
import array


from keras.models import load_model
model_moneydetect = load_model('CNN_MoneyDetect.h5')
# Load and define image - to test
img = load_img('2000d.jpg', target_size=(250,250))
plt.imshow(img)

img=image.img_to_array(img) 
img=img.reshape(1,250,250,3)
img=img.astype('float32')
img=img/255

guess = np.argmax(model_moneydetect.predict(img),axis=1)
print(' This is: ' , dataset_labels[guess])